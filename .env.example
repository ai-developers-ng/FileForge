# Copy this file to .env and fill in the values.
# Generate a strong SECRET_KEY with: python -c "import secrets; print(secrets.token_hex(32))"

# Required
SECRET_KEY=replace-me-with-a-strong-random-secret

# ── File handling ─────────────────────────────────────────────────────────────
# Maximum upload size in megabytes
MAX_FILE_MB=50

# ── Job cleanup ───────────────────────────────────────────────────────────────
# How long to keep completed/failed job data (hours)
CLEANUP_TTL_HOURS=24
# How often to run the cleanup routine (minutes)
CLEANUP_INTERVAL_MINUTES=30

# ── Concurrency ───────────────────────────────────────────────────────────────
# Number of concurrent job workers (inter-job parallelism)
# Tune to: number of CPU cores, or 1 on low-memory machines
WORKER_COUNT=2

# ── OCR quality ───────────────────────────────────────────────────────────────
# DPI used when converting PDF pages to images (higher = better quality, more RAM)
# 300 = recommended, 200 = faster/less RAM, 400 = small-print documents
OCR_DPI=300

# ── OCR parallelism ───────────────────────────────────────────────────────────
# Pages to OCR simultaneously within a single job.
# Each worker runs up to 3 Tesseract processes (~100-200 MB RAM each).
# Recommended: 2 on 4 GB VPS, 4 on 8 GB+ with 4+ CPU cores.
OCR_PAGE_WORKERS=2

# PDF pages converted to images per batch (controls peak RAM during conversion).
# Lower = less RAM, more batches. Higher = more RAM, fewer round-trips.
OCR_BATCH_SIZE=10

# ── Gunicorn (production server) ──────────────────────────────────────────────
# Keep GUNICORN_WORKERS=1 when using the internal ThreadPoolExecutor job queue.
# Increase only if you move job execution out of the web process.
GUNICORN_WORKERS=1
# Threads per gunicorn worker (handles concurrent HTTP requests)
GUNICORN_THREADS=8
